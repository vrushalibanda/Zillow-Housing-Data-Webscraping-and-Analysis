{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "import urllib.error\n",
    "import ssl\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract information of houses on market 40 houses\n",
    "market_houses = []\n",
    "markethouse_url = 'https://www.zillow.com/newark-ca/houses/?searchQueryState={%22pagination%22:{},%22usersSearchTerm%22:%22Newark,%20CA%22,%22mapBounds%22:{%22west%22:-122.16536934228516,%22east%22:-121.89551765771485,%22south%22:37.436669756614464,%22north%22:37.60533202072703},%22regionSelection%22:[{%22regionId%22:49611,%22regionType%22:6}],%22mapZoom%22:12,%22filterState%22:{%22isCondo%22:{%22value%22:false},%22isMultiFamily%22:{%22value%22:false},%22isManufactured%22:{%22value%22:false},%22isLotLand%22:{%22value%22:false},%22isTownhouse%22:{%22value%22:false},%22isApartment%22:{%22value%22:false}},%22isListVisible%22:true,%22isMapVisible%22:true}'\n",
    "market_req = Request(markethouse_url, headers = {'user-Agent':'Mozilla/5.0'})\n",
    "market_text = urlopen(market_req).read().decode(encoding=\"utf-8\", errors='ignore')\n",
    "market_soup = BS(market_text, 'html.parser')\n",
    "for link in market_soup.findAll('a',attrs = {'class':'list-card-link', 'tabindex':\"0\"}, href = True):\n",
    "    market_houses.append(link['href'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(market_houses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a empty dataframe\n",
    "house_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#informations on the first listing page of all 40 houses\n",
    "bds = []\n",
    "bath = []\n",
    "areas = []\n",
    "price_ls = []\n",
    "adr_ls = []\n",
    "\n",
    "\n",
    "req = Request(markethouse_url, headers = {'user-Agent':'Mozilla/5.0'})\n",
    "text = urlopen(req).read().decode(encoding=\"utf8\", errors='ignore')\n",
    "soup = BS(text, 'html.parser')\n",
    "    \n",
    "house_prices = soup.findAll('div', attrs = {'class':'list-card-price'})\n",
    "for price in house_prices:\n",
    "    price_ls.append(price.get_text())\n",
    "\n",
    "\n",
    "    \n",
    "#extract room info\n",
    "lists = soup.findAll('ul', attrs = {'class':'list-card-details'})\n",
    "details = soup.findAll('ul', attrs = {'class':'list-card-details'})\n",
    "#print(len(details))\n",
    "for detail in details:\n",
    "    #print(detail.li)\n",
    "    bds.append(detail.li.get_text())\n",
    "    bath.append(detail.li.next_sibling.get_text())\n",
    "    areas.append(detail.li.next_sibling.next_sibling.get_text())\n",
    "    \n",
    "#extract address info\n",
    "addresses = soup.findAll('address', attrs = {'class':'list-card-addr'})\n",
    "for address in addresses:\n",
    "    adr_ls.append(address.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-43cb1fb92947>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mhv_ls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'None'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;31m#print(hv_ls)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mlotsize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhv_ls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[0mhoa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhv_ls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0myear\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhv_ls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#details after opening each url of a house\n",
    "\n",
    "lotsize = []\n",
    "year = []\n",
    "ac = []\n",
    "heat = []\n",
    "park = []\n",
    "price_sqft = []\n",
    "hoa = []\n",
    "\n",
    "elem = []\n",
    "mid =[]\n",
    "high=[]\n",
    "\n",
    "elem_s=[]\n",
    "mid_s=[]\n",
    "high_s=[]\n",
    "\n",
    "neighborhood = []\n",
    "\n",
    "for url in market_houses:\n",
    "    req = Request(url, headers = {'user-Agent':'Mozilla/5.0'})\n",
    "    text = urlopen(req).read().decode(encoding=\"utf-8\", errors='ignore')\n",
    "    soup = BS(text, 'html.parser')\n",
    "    \n",
    "    #iterate all house url on first page, and scrape the lot_size, year, ac, heater, garage, price/sqft info\n",
    "    home_values = soup.findAll('span', attrs = {'class':'ds-body ds-home-fact-value'})\n",
    "    hv_ls = []\n",
    "    for value in home_values:\n",
    "        hv_ls.append(value.get_text())   \n",
    "    if len(hv_ls) == 0:\n",
    "        hv_ls = ['None']*7\n",
    "    #print(hv_ls)   \n",
    "    lotsize.append(hv_ls[6])\n",
    "    hoa.append(hv_ls[5])\n",
    "    year.append(hv_ls[1])\n",
    "    ac.append(hv_ls[3])\n",
    "    heat.append(hv_ls[2])\n",
    "    park.append(hv_ls[4])\n",
    "    price_sqft.append(hv_ls[-1])\n",
    "\n",
    "    #scrape school info    \n",
    "    schools = soup.findAll('div', attrs = {'class':'ds-nearby-schools-list'})\n",
    "    if len(schools) == 0:\n",
    "        scl = ['None', 'None', 'None']\n",
    "        scl_score = ['None', 'None', 'None']\n",
    "    elif len(list(schools[0].children)) == 0:\n",
    "        scl = ['None', 'None', 'None']\n",
    "        scl_score = ['None', 'None', 'None']\n",
    "    else:\n",
    "        scl = ['None', 'None', 'None']\n",
    "        scl_score = ['None', 'None', 'None']\n",
    "        for school in schools[0].children:  \n",
    "            #print(school.span.get_text())\n",
    "            grade = school.findAll('span')[3].get_text()\n",
    "            if grade == 'K-6' or grade == 'K-5' or grade == 'K-8':\n",
    "                scl[0] = school.a.get_text()\n",
    "                scl_score[0] = school.span.get_text()\n",
    "            if grade == '7-8' or grade == '6-8':\n",
    "                scl[1] = school.a.get_text()\n",
    "                scl_score[1] = school.span.get_text()\n",
    "            if grade == '9-12':\n",
    "                scl[2] = school.a.get_text()\n",
    "                scl_score[2] = school.span.get_text()\n",
    "    elem.append(scl[0])\n",
    "    mid.append(scl[1])\n",
    "    high.append(scl[2])\n",
    "    elem_s.append(scl_score[0])\n",
    "    mid_s.append(scl_score[1])\n",
    "    high_s.append(scl_score[2])\n",
    "    \n",
    "    #scrape Neighborhood info\n",
    "    \n",
    "    nbs = soup.findAll('li', attrs = {'class':'ds-data-view-item'})\n",
    "    for nb in soup.findAll(string=re.compile(\"^Neighborhood:\")):\n",
    "        neighborhood.append(nb.split(':')[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hv_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(neighborhood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a columns to the empty dataframe\n",
    "house_df['bds']=bds\n",
    "house_df['bath']=bath\n",
    "house_df['areas']=areas\n",
    "house_df['lot_size']=lotsize\n",
    "house_df['year_built']=year\n",
    "house_df['a/c']=ac\n",
    "house_df['heater']=heat\n",
    "house_df['garage']=park\n",
    "house_df['price/sqft']=price_sqft\n",
    "house_df['elem_score']=elem_s\n",
    "house_df['middle_score']=mid_s\n",
    "house_df['high_score']=high_s\n",
    "house_df['elem_school'] = elem\n",
    "house_df['middle_school'] = mid\n",
    "house_df['high_school'] = high\n",
    "house_df['pricllllle'] = price_ls\n",
    "house_df['HOA'] = hoa\n",
    "house_df['address']=adr_ls\n",
    "house_df['neighborhood']=neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data on CSV file\n",
    "house_df.to_csv('market_houses_Newark.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find all links of 80 sold houses on the first 2 page of the search, sorted by newest to oldest\n",
    "soldpage_urls = ['https://www.zillow.com/newark-ca/sold/house_type/?searchQueryState={%22pagination%22:{},%22mapBounds%22:{%22west%22:-122.16536934228516,%22east%22:-121.89551765771485,%22south%22:37.436669756614464,%22north%22:37.60533202072703},%22regionSelection%22:[{%22regionId%22:49611,%22regionType%22:6}],%22isMapVisible%22:true,%22mapZoom%22:12,%22filterState%22:{%22sortSelection%22:{%22value%22:%22globalrelevanceex%22},%22isForSaleByAgent%22:{%22value%22:false},%22isForSaleByOwner%22:{%22value%22:false},%22isNewConstruction%22:{%22value%22:false},%22isForSaleForeclosure%22:{%22value%22:false},%22isComingSoon%22:{%22value%22:false},%22isAuction%22:{%22value%22:false},%22isPreMarketForeclosure%22:{%22value%22:false},%22isPreMarketPreForeclosure%22:{%22value%22:false},%22isRecentlySold%22:{%22value%22:true},%22isCondo%22:{%22value%22:false},%22isMultiFamily%22:{%22value%22:false},%22isManufactured%22:{%22value%22:false},%22isLotLand%22:{%22value%22:false},%22isTownhouse%22:{%22value%22:false},%22isApartment%22:{%22value%22:false}},%22isListVisible%22:true}',\n",
    "                 'https://www.zillow.com/newark-ca/sold/house_type/2_p/?searchQueryState={%22pagination%22:{%22currentPage%22:2},%22usersSearchTerm%22:%22Newark,%20CA%22,%22mapBounds%22:{%22west%22:-122.16536934228516,%22east%22:-121.89551765771485,%22south%22:37.436669756614464,%22north%22:37.60533202072703},%22regionSelection%22:[{%22regionId%22:49611,%22regionType%22:6}],%22mapZoom%22:12,%22isMapVisible%22:true,%22filterState%22:{%22isCondo%22:{%22value%22:false},%22isMultiFamily%22:{%22value%22:false},%22isManufactured%22:{%22value%22:false},%22isLotLand%22:{%22value%22:false},%22isTownhouse%22:{%22value%22:false},%22isApartment%22:{%22value%22:false},%22isRecentlySold%22:{%22value%22:true},%22isForSaleByAgent%22:{%22value%22:false},%22isForSaleByOwner%22:{%22value%22:false},%22isNewConstruction%22:{%22value%22:false},%22isComingSoon%22:{%22value%22:false},%22isAuction%22:{%22value%22:false},%22isForSaleForeclosure%22:{%22value%22:false},%22isPreMarketForeclosure%22:{%22value%22:false},%22isPreMarketPreForeclosure%22:{%22value%22:false}},%22isListVisible%22:true}']\n",
    "sold_urllist = []\n",
    "for url in soldpage_urls:\n",
    "    req = Request(url, headers = {'user-Agent':'Mozilla/5.0'})\n",
    "    text = urlopen(req).read().decode(encoding=\"utf-8\", errors='ignore')\n",
    "    soup = BS(text, 'html.parser')\n",
    "    for link in soup.findAll('a',attrs = {'class':'list-card-link', 'tabindex':\"0\"}, href = True):\n",
    "        \n",
    "        sold_urllist.append(link['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sold_urllist[40:80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "soldhouse_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#informations on the first listing page of all 40 houses\n",
    "bds_sold = []\n",
    "bath_sold = []\n",
    "areas_sold = []\n",
    "price_ls_sold = []\n",
    "adr_ls_sold = []\n",
    "sold_dates = []\n",
    "for url in soldpage_urls:\n",
    "    req_sold = Request(url, headers = {'user-Agent':'Mozilla/5.0'})\n",
    "    text_sold = urlopen(req_sold).read().decode(encoding=\"utf8\", errors='ignore')\n",
    "    soup_sold = BS(text_sold, 'html.parser')\n",
    "    \n",
    "    soldhouse_prices = soup_sold.findAll('div', attrs = {'class':'list-card-price'})\n",
    "    for price in soldhouse_prices:\n",
    "        price_ls_sold.append(price.get_text())\n",
    "\n",
    "\n",
    "    \n",
    "    #extract room info\n",
    "    lists_sold = soup_sold.findAll('ul', attrs = {'class':'list-card-details'})\n",
    "    details_sold = soup_sold.findAll('ul', attrs = {'class':'list-card-details'})\n",
    "    #print(len(details))\n",
    "    for detail in details_sold:\n",
    "        #print(detail.li)\n",
    "        bds_sold.append(detail.li.get_text())\n",
    "        bath_sold.append(detail.li.next_sibling.get_text())\n",
    "        areas_sold.append(detail.li.next_sibling.next_sibling.get_text())\n",
    "    \n",
    "    #extract address info\n",
    "    addresses_sold = soup_sold.findAll('address', attrs = {'class':'list-card-addr'})\n",
    "    for address in addresses_sold:\n",
    "        adr_ls_sold.append(address.get_text())\n",
    "        \n",
    "    #extract sold dates\n",
    "    dates = soup_sold.findAll('div', attrs={'class':'list-card-variable-text list-card-img-overlay'})\n",
    "    for date in dates:\n",
    "        sold_dates.append(date.get_text().split(' ')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sold_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#details after opening each url of a house\n",
    "lotsize_sold1 = []\n",
    "year_sold1 = []\n",
    "ac_sold1 = []\n",
    "heat_sold1 = []\n",
    "park_sold1 = []\n",
    "\n",
    "hoa_sold1 = []\n",
    "\n",
    "elem_sold1 = []\n",
    "mid_sold1 =[]\n",
    "high_sold1=[]\n",
    "\n",
    "elem_s_sold1=[]\n",
    "mid_s_sold1=[]\n",
    "high_s_sold1=[]\n",
    "\n",
    "neighborhood_sold1 = []\n",
    "\n",
    "for url in sold_urllist[0:40]:\n",
    "    #print(url)\n",
    "    req_sold1 = Request(url, headers = {'user-Agent':'Mozilla/5.0'})\n",
    "    text_sold1 = urlopen(req_sold1).read().decode(encoding=\"utf-8\", errors='ignore')\n",
    "    soup_sold1 = BS(text_sold1, 'html.parser')\n",
    "    \n",
    "    #iterate all house url on first page, and scrape the lot_size, year, ac, heater, garage, price/sqft info\n",
    "    home_values_sold1 = soup_sold1.findAll('div', attrs = {'class':'fact-value'})\n",
    "    hv_ls_sold1 = []\n",
    "    for value in home_values_sold1:\n",
    "        hv_ls_sold1.append(value.get_text())   \n",
    "    if len(hv_ls_sold1) == 0:\n",
    "        hv_ls_sold1 = ['None']*7\n",
    "    #print(hv_ls_sold1)   \n",
    "    lotsize_sold1.append(hv_ls_sold1[6])\n",
    "    hoa_sold1.append(hv_ls_sold1[5])\n",
    "    year_sold1.append(hv_ls_sold1[1])\n",
    "    ac_sold1.append(hv_ls_sold1[3])\n",
    "    heat_sold1.append(hv_ls_sold1[2])\n",
    "    park_sold1.append(hv_ls_sold1[4])\n",
    "\n",
    "    \n",
    "\n",
    "    #scrape school info    \n",
    "    schools1 = soup_sold1.findAll('li', attrs = {'class':'nearby-school assigned-school clearfix'})\n",
    "    if len(schools1) == 0:\n",
    "        scl1 = ['None', 'None', 'None']\n",
    "        scl_score1 = ['None', 'None', 'None']\n",
    "    else:\n",
    "        scl1 = ['None', 'None', 'None']\n",
    "        scl_score1 = ['None', 'None', 'None']\n",
    "        for school in schools1:  \n",
    "            #print(school.span.get_text())\n",
    "            grade = school.findAll('div')[5].get_text()\n",
    "            if grade == 'K-6' or grade == 'K-5' or grade == 'K-8':\n",
    "                scl1[0] = school.a.get_text()\n",
    "                scl_score1[0] = school.span.get_text()\n",
    "            if grade == '7-8' or grade == '6-8':\n",
    "                scl1[1] = school.a.get_text()\n",
    "                scl_score1[1] = school.span.get_text()\n",
    "            if grade == '9-12':\n",
    "                scl1[2] = school.a.get_text()\n",
    "                scl_score1[2] = school.span.get_text()\n",
    "    elem_sold1.append(scl1[0])\n",
    "    mid_sold1.append(scl1[1])\n",
    "    high_sold1.append(scl1[2])\n",
    "    elem_s_sold1.append(scl_score1[0])\n",
    "    mid_s_sold1.append(scl_score1[1])\n",
    "    high_s_sold1.append(scl_score1[2])\n",
    "    \n",
    "    #scrape Neiborhood info\n",
    "    for nb in soup_sold1.findAll(string=re.compile(\"^Neighborhood:\")):\n",
    "        neighborhood_sold1.append(nb.split(':')[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neighborhood_sold1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#details after opening each url of a house\n",
    "lotsize_sold2 = []\n",
    "year_sold2 = []\n",
    "ac_sold2 = []\n",
    "heat_sold2 = []\n",
    "park_sold2 = []\n",
    "\n",
    "hoa_sold2 = []\n",
    "bath_sold2 = []\n",
    "\n",
    "elem_sold2 = []\n",
    "mid_sold2 =[]\n",
    "high_sold2=[]\n",
    "\n",
    "elem_s_sold2=[]\n",
    "mid_s_sold2=[]\n",
    "high_s_sold2=[]\n",
    "\n",
    "neighborhood_sold2 = []\n",
    "\n",
    "for url in sold_urllist[40:80]:\n",
    "    #print(url)\n",
    "    req_sold2 = Request(url, headers = {'user-Agent':'Mozilla/5.0'})\n",
    "    text_sold2 = urlopen(req_sold2).read().decode(encoding=\"utf-8\", errors='ignore')\n",
    "    soup_sold2 = BS(text_sold2, 'html.parser')\n",
    "    \n",
    "    #iterate all house url on first page, and scrape the lot_size, year, ac, heater, garage, price/sqft info\n",
    "    home_values_sold2 = soup_sold2.findAll('div', attrs = {'class':'fact-value'})\n",
    "    hv_ls_sold2 = []\n",
    "    for value in home_values_sold2:\n",
    "        hv_ls_sold2.append(value.get_text())   \n",
    "    if len(hv_ls_sold2) == 0:\n",
    "        hv_ls_sold2 = ['None']*7\n",
    "    #print(hv_ls_sold2)   \n",
    "    lotsize_sold2.append(hv_ls_sold2[6])\n",
    "    hoa_sold2.append(hv_ls_sold2[5])\n",
    "    year_sold2.append(hv_ls_sold2[1])\n",
    "    ac_sold2.append(hv_ls_sold2[3])\n",
    "    heat_sold2.append(hv_ls_sold2[2])\n",
    "    park_sold2.append(hv_ls_sold2[4])\n",
    "\n",
    "    \n",
    "\n",
    "    #scrape school info    \n",
    "    schools2 = soup_sold2.findAll('li', attrs = {'class':'nearby-school assigned-school clearfix'})\n",
    "    if len(schools2) == 0:\n",
    "        scl2 = ['None', 'None', 'None']\n",
    "        scl_score2 = ['None', 'None', 'None']\n",
    "    else:\n",
    "        scl2 = ['None', 'None', 'None']\n",
    "        scl_score2 = ['None', 'None', 'None']\n",
    "        for school in schools2:  \n",
    "            #print(school.span.get_text())\n",
    "            grade = school.findAll('div')[5].get_text()\n",
    "            if grade == 'K-6' or grade == 'K-5' or grade == 'K-8':\n",
    "                scl2[0] = school.a.get_text()\n",
    "                scl_score2[0] = school.span.get_text()\n",
    "            if grade == '7-8' or grade == '6-8':\n",
    "                scl2[1] = school.a.get_text()\n",
    "                scl_score2[1] = school.span.get_text()\n",
    "            if grade == '9-12':\n",
    "                scl2[2] = school.a.get_text()\n",
    "                scl_score2[2] = school.span.get_text()\n",
    "    elem_sold2.append(scl2[0])\n",
    "    mid_sold2.append(scl2[1])\n",
    "    high_sold2.append(scl2[2])\n",
    "    elem_s_sold2.append(scl_score2[0])\n",
    "    mid_s_sold2.append(scl_score2[1])\n",
    "    high_s_sold2.append(scl_score2[2])\n",
    "    \n",
    "    #scrape Neiborhood info\n",
    "    for nb in soup_sold2.findAll(string=re.compile(\"^Neighborhood:\")):\n",
    "        neighborhood_sold2.append(nb.split(':')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(neighborhood_sold2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lotsize_sold=lotsize_sold1+lotsize_sold2\n",
    "year_sold=year_sold1+year_sold2\n",
    "ac_sold=ac_sold1+ac_sold2\n",
    "heat_sold=heat_sold1+heat_sold2\n",
    "park_sold=park_sold1+park_sold2\n",
    "hoa_sold=hoa_sold1+hoa_sold2\n",
    "elem_sold=elem_sold1+elem_sold2\n",
    "mid_sold=mid_sold1+mid_sold2\n",
    "high_sold=high_sold1+high_sold2\n",
    "elem_s_sold=elem_s_sold1+elem_s_sold2\n",
    "mid_s_sold=mid_s_sold1+mid_s_sold2\n",
    "high_s_sold=high_s_sold1+high_s_sold2\n",
    "neighborhood_sold=neighborhood_sold1+neighborhood_sold2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a columns to the empty dataframe\n",
    "soldhouse_df['bds']=bds_sold\n",
    "soldhouse_df['bath']=bath_sold\n",
    "soldhouse_df['areas']=areas_sold\n",
    "soldhouse_df['lot_size']=lotsize_sold\n",
    "soldhouse_df['year_built']=year_sold\n",
    "soldhouse_df['a/c']=ac_sold\n",
    "soldhouse_df['heater']=heat_sold\n",
    "soldhouse_df['garage']=park_sold\n",
    "soldhouse_df['elem_score']=elem_s_sold\n",
    "soldhouse_df['middle_score']=mid_s_sold\n",
    "soldhouse_df['high_score']=high_s_sold\n",
    "soldhouse_df['elem_school'] = elem_sold\n",
    "soldhouse_df['middle_school'] = mid_sold\n",
    "soldhouse_df['high_school'] = high_sold\n",
    "soldhouse_df['sold_price'] = price_ls_sold\n",
    "soldhouse_df['HOA'] = hoa_sold\n",
    "soldhouse_df['address']=adr_ls_sold\n",
    "soldhouse_df['date_sold']=sold_dates\n",
    "soldhouse_df['neighborhood']=neighborhood_sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bath_sold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soldhouse_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bath_sold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "soldhouse_df.to_csv('sold_houses_Newark.csv',sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
